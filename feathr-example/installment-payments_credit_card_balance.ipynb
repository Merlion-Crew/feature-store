{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feathr Feature Store on Home Credit\n",
    "\n",
    "This notebook illustrates the use of Feature Store to create a model for home credits. It includes these steps:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite: Install Feathr\n",
    "\n",
    "Install Feathr using pip:\n",
    "\n",
    "`pip install -U feathr pandavro scikit-learn`\n",
    "\n",
    "Or if you want to use the latest Feathr code from GitHub:\n",
    "\n",
    "`pip install -I git+https://github.com/linkedin/feathr.git#subdirectory=feathr_project pandavro scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feathr in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (0.5.1)\n",
      "Requirement already satisfied: pandavro in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (1.7.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: redis in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (4.3.1)\n",
      "Requirement already satisfied: azure-keyvault-secrets in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (4.4.0)\n",
      "Requirement already satisfied: pyhocon in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (0.3.59)\n",
      "Requirement already satisfied: Jinja2 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (3.1.2)\n",
      "Requirement already satisfied: pyyaml in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (6.0)\n",
      "Requirement already satisfied: tqdm in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (4.64.0)\n",
      "Requirement already satisfied: pandas in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (1.2.5)\n",
      "Requirement already satisfied: requests in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (2.27.1)\n",
      "Requirement already satisfied: azure-synapse-spark in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (0.7.0)\n",
      "Requirement already satisfied: google>=3.0.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (3.0.0)\n",
      "Requirement already satisfied: py4j in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (0.10.9.3)\n",
      "Requirement already satisfied: google-api-python-client>=2.41.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (2.48.0)\n",
      "Requirement already satisfied: loguru in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (0.6.0)\n",
      "Requirement already satisfied: pyapacheatlas in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (0.12.0)\n",
      "Requirement already satisfied: pyarrow in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (8.0.0)\n",
      "Requirement already satisfied: confluent-kafka in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (1.8.2)\n",
      "Requirement already satisfied: deltalake in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (0.5.7)\n",
      "Requirement already satisfied: pyspark>=3.1.2 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (3.2.1)\n",
      "Requirement already satisfied: azure-storage-file-datalake>=12.5.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (12.6.0)\n",
      "Requirement already satisfied: avro in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (1.11.0)\n",
      "Requirement already satisfied: Click in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (8.1.3)\n",
      "Requirement already satisfied: azure-core<=1.22.1 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (1.22.1)\n",
      "Requirement already satisfied: graphlib-backport in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (1.0.3)\n",
      "Requirement already satisfied: databricks-cli in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (0.16.6)\n",
      "Requirement already satisfied: python-snappy in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (0.6.1)\n",
      "Requirement already satisfied: azure-identity in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from feathr) (4.2.0)\n",
      "Requirement already satisfied: fastavro==1.5.1 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from pandavro) (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from pandavro) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from scikit-learn) (1.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from azure-core<=1.22.1->feathr) (1.16.0)\n",
      "Requirement already satisfied: azure-storage-blob<13.0.0,>=12.10.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from azure-storage-file-datalake>=12.5.0->feathr) (12.11.0)\n",
      "Requirement already satisfied: msrest>=0.6.21 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from azure-storage-file-datalake>=12.5.0->feathr) (0.6.21)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from google>=3.0.0->feathr) (4.11.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from google-api-python-client>=2.41.0->feathr) (2.7.3)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from google-api-python-client>=2.41.0->feathr) (0.20.4)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from google-api-python-client>=2.41.0->feathr) (0.1.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from google-api-python-client>=2.41.0->feathr) (4.1.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from google-api-python-client>=2.41.0->feathr) (2.6.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from pandas->feathr) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from pandas->feathr) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from requests->feathr) (2022.5.18)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from requests->feathr) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from requests->feathr) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from requests->feathr) (2.0.12)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from azure-identity->feathr) (1.0.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from azure-identity->feathr) (37.0.2)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.12.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from azure-identity->feathr) (1.17.0)\n",
      "Requirement already satisfied: azure-common~=1.1 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from azure-keyvault-secrets->feathr) (1.1.28)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from databricks-cli->feathr) (2.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from databricks-cli->feathr) (3.2.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from databricks-cli->feathr) (0.8.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from Jinja2->feathr) (2.1.1)\n",
      "Requirement already satisfied: openpyxl>=3.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from pyapacheatlas->feathr) (3.0.9)\n",
      "Requirement already satisfied: pyparsing~=2.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from pyhocon->feathr) (2.4.7)\n",
      "Requirement already satisfied: deprecated>=1.2.3 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from redis->feathr) (1.2.13)\n",
      "Requirement already satisfied: packaging>=20.4 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from redis->feathr) (21.3)\n",
      "Requirement already satisfied: async-timeout>=4.0.2 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from redis->feathr) (4.0.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from cryptography>=2.5->azure-identity->feathr) (1.15.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from deprecated>=1.2.3->redis->feathr) (1.14.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=2.41.0->feathr) (1.56.1)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=2.41.0->feathr) (3.20.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=2.41.0->feathr) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=2.41.0->feathr) (5.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=2.41.0->feathr) (0.2.8)\n",
      "Requirement already satisfied: portalocker<3,>=1.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity->feathr) (2.4.0)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from msrest>=0.6.21->azure-storage-file-datalake>=12.5.0->feathr) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from msrest>=0.6.21->azure-storage-file-datalake>=12.5.0->feathr) (1.3.1)\n",
      "Requirement already satisfied: et-xmlfile in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from openpyxl>=3.0->pyapacheatlas->feathr) (1.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from beautifulsoup4->google>=3.0.0->feathr) (2.3.2.post1)\n",
      "Requirement already satisfied: pycparser in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity->feathr) (2.21)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/dasorbit/projects/merlion-feature-store-scenario/.venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=2.41.0->feathr) (0.4.8)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U feathr pandavro scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite: Configure the required environment\n",
    "\n",
    "In the first step (Provision cloud resources), you should have provisioned all the required cloud resources. If you use Feathr CLI to create a workspace, you should have a folder with a file called `feathr_config.yaml` in it with all the required configurations. Otherwise, update the configuration below.\n",
    "\n",
    "The code below will write this configuration string to a temporary location and load it to Feathr. Please still refer to [feathr_config.yaml](https://github.com/linkedin/feathr/blob/main/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml) and use that as the source of truth. It should also have more explanations on the meaning of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "yaml_config = \"\"\"\n",
    "# Please refer to https://github.com/linkedin/feathr/blob/main/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml for explanations on the meaning of each field.\n",
    "api_version: 1\n",
    "project_config:\n",
    "  project_name: 'feathr_home_credit'\n",
    "  required_environment_variables:\n",
    "    - 'REDIS_PASSWORD'\n",
    "    - 'AZURE_CLIENT_ID'\n",
    "    - 'AZURE_TENANT_ID'\n",
    "    - 'AZURE_CLIENT_SECRET'\n",
    "offline_store:\n",
    "  adls:\n",
    "    adls_enabled: tru\n",
    "  wasb:\n",
    "    wasb_enabled: true\n",
    "  s3:\n",
    "    s3_enabled: false\n",
    "    s3_endpoint: 's3.amazonaws.com'\n",
    "  jdbc:\n",
    "    jdbc_enabled: false\n",
    "    jdbc_database: 'feathrtestdb'\n",
    "    jdbc_table: 'feathrtesttable'\n",
    "  snowflake:\n",
    "    url: \"dqllago-ol19457.snowflakecomputing.com\"\n",
    "    user: \"feathrintegration\"\n",
    "    role: \"ACCOUNTADMIN\"\n",
    "spark_config:\n",
    "  spark_cluster: 'azure_synapse'\n",
    "  spark_result_output_parts: '1'\n",
    "  azure_synapse:\n",
    "    dev_url: \"https://feathrhomecreditcaspark.dev.azuresynapse.net\"\n",
    "    pool_name: \"spark31\"\n",
    "    # workspace dir for storing all the required configuration files and the jar resources\n",
    "    workspace_dir: \"abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/\"\n",
    "    executor_size: \"Small\"\n",
    "    executor_num: 4\n",
    "    feathr_runtime_location: wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar\n",
    "  databricks:\n",
    "    workspace_instance_url: 'https://adb-6885802458123232.12.azuredatabricks.net/'\n",
    "    workspace_token_value: ''\n",
    "    config_template: {'run_name':'','new_cluster':{'spark_version':'9.1.x-scala2.12','node_type_id':'Standard_D3_v2','num_workers':2,'spark_conf':{}},'libraries':[{'jar':''}],'spark_jar_task':{'main_class_name':'','parameters':['']}}\n",
    "    work_dir: 'dbfs:/feathr_getting_started'\n",
    "    feathr_runtime_location: wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar\n",
    "online_store:\n",
    "  redis:\n",
    "    host: 'feathrhomecreditcaredis.redis.cache.windows.net'\n",
    "    port: 6380\n",
    "    ssl_enabled: True\n",
    "feature_registry:\n",
    "  purview:\n",
    "    type_system_initialization: true\n",
    "    purview_name: 'feathrhomecreditcapurview'\n",
    "    delimiter: '__'\n",
    "\"\"\"\n",
    "tmp = tempfile.NamedTemporaryFile(mode='w', delete=False)\n",
    "with open(tmp.name, \"w\") as text_file:\n",
    "    text_file.write(yaml_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the data\n",
    "\n",
    "In this tutorial, we use Feathr Feature Store to create a model that predicts NYC Taxi fares. The dataset comes from [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). The data is as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tempfile\n",
    "from datetime import datetime, timedelta\n",
    "from math import sqrt\n",
    "\n",
    "import pandas as pd\n",
    "import pandavro as pdx\n",
    "from feathr import FeathrClient\n",
    "from feathr import BOOLEAN, FLOAT, INT32, ValueType, STRING\n",
    "from feathr import Feature, DerivedFeature, FeatureAnchor\n",
    "from feathr import BackfillTime, MaterializationSettings\n",
    "from feathr import FeatureQuery, ObservationSettings\n",
    "from feathr import RedisSink\n",
    "from feathr import INPUT_CONTEXT, HdfsSource\n",
    "from feathr import WindowAggTransformation\n",
    "from feathr import TypedKey\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup necessary environment variables\n",
    "\n",
    "You have to setup the environment variables in order to run this sample. More environment variables can be set by referring to [feathr_config.yaml](https://github.com/linkedin/feathr/blob/main/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml) and use that as the source of truth. It should also have more explanations on the meaning of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['REDIS_PASSWORD'] = ''\n",
    "os.environ['AZURE_CLIENT_ID'] = ''\n",
    "os.environ['AZURE_TENANT_ID'] = '' \n",
    "os.environ['AZURE_CLIENT_SECRET'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will initialize a feathr client:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = FeathrClient(config_path=tmp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc pre-processing methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installments payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def installments_payments_preprocessing(df: DataFrame) -> DataFrame:\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    from pyspark import sql\n",
    "\n",
    "    def aggAvgInstalments(df):\n",
    "        df_ = df.copy()\n",
    "        \n",
    "        \n",
    "        df_['AMT_INSTALMENT'] = pd.to_numeric(df_['AMT_INSTALMENT'])\n",
    "        df_['AMT_PAYMENT'] = pd.to_numeric(df_['AMT_PAYMENT'])\n",
    "        \n",
    "        df_['INSTALMENT_MISSED'] = (df_['AMT_INSTALMENT'] > df_['AMT_PAYMENT']).astype(int)\n",
    "        df_['AMT_UNPAID'] = df_['AMT_INSTALMENT'] - df_['AMT_PAYMENT']\n",
    "        df_['PERC_UNPAID'] = df_['AMT_UNPAID']/df_['AMT_INSTALMENT']\n",
    "        \n",
    "        df_ = df_.fillna(0)\n",
    "        agg = df_.groupby(\"SK_ID_CURR\")\n",
    "        # percentage of missed payments\n",
    "        missed_instalments = agg['INSTALMENT_MISSED'].agg(lambda x: x.sum()/x.count()). \\\n",
    "            reset_index().set_index(\"SK_ID_CURR\")\n",
    "        # percentage of payments difference for each missed payment\n",
    "        avg_percent_unpaid = agg['PERC_UNPAID'].mean().reset_index().set_index(\"SK_ID_CURR\")\n",
    "        # average payments difference for each missed payment\n",
    "        avg_unpaid = agg['AMT_UNPAID'].mean().reset_index().set_index(\"SK_ID_CURR\")\n",
    "        final_df = missed_instalments\n",
    "        final_df = final_df.join(avg_percent_unpaid, on='SK_ID_CURR')\n",
    "        final_df = final_df.join(avg_unpaid,on=\"SK_ID_CURR\")\n",
    "        return final_df\n",
    "\n",
    "    # add a TRAN_DATE column with a static date\n",
    "    df = df.withColumn(\"TRAN_DATE\", lit(datetime.datetime(2021,1,1,11,34,44).strftime('%Y-%m-%d %X')))\n",
    "\n",
    "    df_org = df.toPandas()\n",
    "\n",
    "    df_aggAvgInstalments = aggAvgInstalments(df_org)\n",
    "\n",
    "    # results df would be merge to the original df\n",
    "    df_result = pd.merge(df_org, df_aggAvgInstalments, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    # merging df with same column name would result a columnname with a suffix of `_x` and `_y`.\n",
    "    # Renaming the column name with suffix `_x` to retain the original column name\n",
    "    df_result.columns = df_result.columns.str.rstrip(\"_x\")\n",
    "\n",
    "    \n",
    "    # convert panda to spark dataframe\n",
    "    spark_session = sql.SparkSession.builder.appName(\"pdf to sdf\").getOrCreate()\n",
    "    \n",
    "    return spark_session.createDataFrame(df_result)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature definition for Installments payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# source for pass through features\n",
    "# \"TRAN_DATE\" column created on on the \"datasource_prepocessing\" method.\n",
    "installments_payments_source_core = HdfsSource(name=\"installmentsPaymentsSourceCore\",\n",
    "                          path=\"abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/home_credit_data/installments_payments.csv\",\n",
    "                          preprocessing=installments_payments_preprocessing,\n",
    "                          event_timestamp_column=\"TRAN_DATE\",\n",
    "                          timestamp_format=\"yyyy-MM-dd HH:mm:ss\"\n",
    "                          )\n",
    "\n",
    "# key definition for installments payments\n",
    "key_SK_ID_CURR = TypedKey(key_column=\"SK_ID_CURR\",\n",
    "                       key_column_type=ValueType.INT32,\n",
    "                       description=\"SK ID CURR\",\n",
    "                       full_name=\"installments_payments.SK_ID_CURR\")\n",
    "\n",
    "# pass through columns of Installments payments CSV\n",
    "# columns Installments payments\n",
    "f_SK_ID_PREV = Feature(name=\"f_SK_ID_PREV\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"SK_ID_PREV\")\n",
    "f_SK_ID_CURR = Feature(name=\"f_SK_ID_CURR\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"SK_ID_CURR\")\n",
    "f_NUM_INSTALMENT_VERSION = Feature(name=\"f_NUM_INSTALMENT_VERSION\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"NUM_INSTALMENT_VERSION\")\n",
    "f_NUM_INSTALMENT_NUMBER = Feature(name=\"f_NUM_INSTALMENT_NUMBER\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"NUM_INSTALMENT_NUMBER\")\n",
    "f_DAYS_INSTALMENT = Feature(name=\"f_DAYS_INSTALMENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"DAYS_INSTALMENT\")\n",
    "f_DAYS_ENTRY_PAYMENT = Feature(name=\"f_DAYS_ENTRY_PAYMENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"DAYS_ENTRY_PAYMENT\")\n",
    "f_AMT_INSTALMENT = Feature(name=\"f_AMT_INSTALMENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_INSTALMENT\")\n",
    "f_AMT_PAYMENT = Feature(name=\"f_AMT_PAYMENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_PAYMENT\")\n",
    "\n",
    "\n",
    "\n",
    "f_AMT_UNPAID = Feature(name=\"f_AMT_UNPAID\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_UNPAID\")\n",
    "                  \n",
    "\n",
    "features_installments_payments_core=[\n",
    "  f_SK_ID_PREV,\n",
    "  f_SK_ID_CURR,\n",
    "  f_NUM_INSTALMENT_VERSION,\n",
    "  f_NUM_INSTALMENT_NUMBER,\n",
    "  f_DAYS_INSTALMENT,\n",
    "  f_DAYS_ENTRY_PAYMENT,\n",
    "  f_AMT_INSTALMENT,\n",
    "  f_AMT_PAYMENT,\n",
    "\n",
    "  f_AMT_UNPAID\n",
    "  ]\n",
    "\n",
    "anchor_installments_payments_core = FeatureAnchor(name=\"anchor_installments_payments_core\",\n",
    "                                source=installments_payments_source_core, #INPUT_CONTEXT,\n",
    "                                features=features_installments_payments_core)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_card_balance_preprocessing(df: DataFrame) -> DataFrame:\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    from pyspark import sql\n",
    "\n",
    "    def avgCreditBalance(df):\n",
    "        df['AMT_BALANCE'] = pd.to_numeric(df['AMT_BALANCE'])\n",
    "        return df.groupby('SK_ID_CURR')['AMT_BALANCE'].mean()\n",
    "    \n",
    "    def creditCardBalanceRollingBalance(df):\n",
    "        df_final = df.copy()\n",
    "        df_final = df_final.sort_values(by=\"MONTHS_BALANCE\")\n",
    "        df_final = df_final.groupby(\"SK_ID_CURR\")['AMT_BALANCE'].agg(\n",
    "            lambda x: x.ewm(span=x.shape[0], adjust=False).mean().mean()\n",
    "        )\n",
    "        # print(df_final.columns.values.tolist())\n",
    "        df_final = df_final.reset_index(name=\"CREDIT_CARD_BALANCE_EMA_AVG\")\n",
    "        df_final = df_final.set_index('SK_ID_CURR')\n",
    "        return df_final\n",
    "    \n",
    "    def creditCardFeatures(credit_card_balance):\n",
    "        dfs = []\n",
    "        dfs.append(avgCreditBalance(credit_card_balance))\n",
    "        dfs.append(creditCardBalanceRollingBalance(credit_card_balance))\n",
    "        final_df = dfs.pop()\n",
    "        while dfs:\n",
    "            final_df = final_df.join(dfs.pop(),on='SK_ID_CURR')\n",
    "        return final_df\n",
    "\n",
    "    # add a TRAN_DATE column with a static date\n",
    "    df = df.withColumn(\"TRAN_DATE\", lit(datetime.datetime(2021,1,1,11,34,44).strftime('%Y-%m-%d %X')))\n",
    "    df_org = df.toPandas()\n",
    "\n",
    "    df_result = creditCardFeatures(df_org)\n",
    "\n",
    "    # results df would be merge to the original df\n",
    "    df_result = pd.merge(df_org, df_result, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    # merging df with same column name would result a columnname with a suffix of `_x` and `_y`.\n",
    "    # Renaming the column name with suffix `_x` to retain the original column name\n",
    "    df_result.columns = df_result.columns.str.rstrip(\"_x\")\n",
    "    \n",
    "    # convert panda to spark dataframe\n",
    "    spark_session = sql.SparkSession.builder.appName(\"pdf to sdf\").getOrCreate()\n",
    "    \n",
    "    return spark_session.createDataFrame(df_result)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature definition for Credit Card Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# source for pass through features\n",
    "# \"TRAN_DATE\" column created on on the \"datasource_prepocessing\" method.\n",
    "credit_card_balance_source_core = HdfsSource(name=\"creditCardBalanceSourceCore\",\n",
    "                          path=\"abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/home_credit_data/credit_card_balance.csv\",\n",
    "                          preprocessing=credit_card_balance_preprocessing,\n",
    "                          event_timestamp_column=\"TRAN_DATE\",\n",
    "                          timestamp_format=\"yyyy-MM-dd HH:mm:ss\"\n",
    "                          )\n",
    "\n",
    "# key definition for installments payments\n",
    "# key_SK_ID_CURR = TypedKey(key_column=\"SK_ID_CURR\",\n",
    "#                        key_column_type=ValueType.INT32,\n",
    "#                        description=\"SK ID CURR\",\n",
    "#                        full_name=\"credit_card_balance.SK_ID_CURR\")\n",
    "\n",
    "# pass through columns of Installments payments CSV\n",
    "# columns Installments payments\n",
    "f_SK_ID_PREV = Feature(name=\"f_SK_ID_PREV\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"SK_ID_PREV\")\n",
    "f_SK_ID_CURR_CC = Feature(name=\"f_SK_ID_CURR_CC\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"SK_ID_CURR\")\n",
    "f_MONTHS_BALANCE = Feature(name=\"f_MONTHS_BALANCE\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"MONTHS_BALANCE\")\n",
    "f_AMT_BALANCE = Feature(name=\"f_AMT_BALANCE\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_BALANCE\")\n",
    "f_AMT_CREDIT_LIMIT_ACTUAL = Feature(name=\"f_AMT_CREDIT_LIMIT_ACTUAL\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_CREDIT_LIMIT_ACTUAL\")\n",
    "f_AMT_DRAWINGS_ATM_CURRENT = Feature(name=\"f_AMT_DRAWINGS_ATM_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_DRAWINGS_ATM_CURRENT\")\n",
    "f_AMT_DRAWINGS_CURRENT = Feature(name=\"f_AMT_DRAWINGS_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_DRAWINGS_CURRENT\")\n",
    "f_AMT_DRAWINGS_OTHER_CURRENT = Feature(name=\"f_AMT_DRAWINGS_OTHER_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_DRAWINGS_OTHER_CURRENT\")\n",
    "f_AMT_DRAWINGS_POS_CURRENT = Feature(name=\"f_AMT_DRAWINGS_POS_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_DRAWINGS_POS_CURRENT\")\n",
    "f_AMT_INST_MIN_REGULARITY = Feature(name=\"f_AMT_INST_MIN_REGULARITY\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_INST_MIN_REGULARITY\")\n",
    "f_AMT_PAYMENT_CURRENT = Feature(name=\"f_AMT_PAYMENT_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_PAYMENT_CURRENT\")\n",
    "f_AMT_PAYMENT_TOTAL_CURRENT = Feature(name=\"f_AMT_PAYMENT_TOTAL_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_PAYMENT_TOTAL_CURRENT\")\n",
    "f_AMT_RECEIVABLE_PRINCIPAL = Feature(name=\"f_AMT_RECEIVABLE_PRINCIPAL\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_RECEIVABLE_PRINCIPAL\")\n",
    "f_AMT_RECIVABLE = Feature(name=\"f_AMT_RECIVABLE\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_RECIVABLE\")\n",
    "f_AMT_TOTAL_RECEIVABLE = Feature(name=\"f_AMT_TOTAL_RECEIVABLE\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_TOTAL_RECEIVABLE\")\n",
    "f_CNT_DRAWINGS_ATM_CURRENT = Feature(name=\"f_CNT_DRAWINGS_ATM_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"CNT_DRAWINGS_ATM_CURRENT\")\n",
    "f_CNT_DRAWINGS_CURRENT = Feature(name=\"f_CNT_DRAWINGS_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"CNT_DRAWINGS_CURRENT\")\n",
    "f_CNT_DRAWINGS_OTHER_CURRENT = Feature(name=\"f_CNT_DRAWINGS_OTHER_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"CNT_DRAWINGS_OTHER_CURRENT\")\n",
    "f_CNT_DRAWINGS_POS_CURRENT = Feature(name=\"f_CNT_DRAWINGS_POS_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"CNT_DRAWINGS_POS_CURRENT\")\n",
    "f_CNT_INSTALMENT_MATURE_CUM = Feature(name=\"f_CNT_INSTALMENT_MATURE_CUM\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"CNT_INSTALMENT_MATURE_CUM\")\n",
    "f_NAME_CONTRACT_STATUS = Feature(name=\"f_NAME_CONTRACT_STATUS\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"NAME_CONTRACT_STATUS\")\n",
    "f_SK_DPD = Feature(name=\"f_SK_DPD\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"SK_DPD\")\n",
    "f_SK_DPD_DEF = Feature(name=\"f_SK_DPD_DEF\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"SK_DPD_DEF\")\n",
    "\n",
    "\n",
    "f_CREDIT_CARD_BALANCE_EMA_AVG = Feature(name=\"f_CREDIT_CARD_BALANCE_EMA_AVG\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"CREDIT_CARD_BALANCE_EMA_AVG\")\n",
    "\n",
    "\n",
    "\n",
    "features_credit_card_balance_core=[\n",
    "  # f_SK_ID_PREV,\n",
    "  f_SK_ID_CURR_CC,\n",
    "  f_MONTHS_BALANCE,\n",
    "  f_AMT_BALANCE,\n",
    "  f_AMT_CREDIT_LIMIT_ACTUAL,\n",
    "  f_AMT_DRAWINGS_ATM_CURRENT,\n",
    "  f_AMT_DRAWINGS_CURRENT,\n",
    "  f_AMT_DRAWINGS_OTHER_CURRENT,\n",
    "  f_AMT_DRAWINGS_POS_CURRENT,\n",
    "  f_AMT_INST_MIN_REGULARITY,\n",
    "  f_AMT_PAYMENT_CURRENT,\n",
    "  f_AMT_PAYMENT_TOTAL_CURRENT,\n",
    "  f_AMT_RECEIVABLE_PRINCIPAL,\n",
    "  f_AMT_RECIVABLE,\n",
    "  f_AMT_TOTAL_RECEIVABLE,\n",
    "  f_CNT_DRAWINGS_ATM_CURRENT,\n",
    "  f_CNT_DRAWINGS_CURRENT,\n",
    "  f_CNT_DRAWINGS_OTHER_CURRENT,\n",
    "  f_CNT_DRAWINGS_POS_CURRENT,\n",
    "  f_CNT_INSTALMENT_MATURE_CUM,\n",
    "  f_NAME_CONTRACT_STATUS,\n",
    "  f_SK_DPD,\n",
    "  f_SK_DPD_DEF,\n",
    "\n",
    "  f_CREDIT_CARD_BALANCE_EMA_AVG\n",
    "\n",
    "  ]\n",
    "\n",
    "anchor_credit_card_balance_core = FeatureAnchor(name=\"anchor_credit_card_balance_core\",\n",
    "                                source=credit_card_balance_source_core, #INPUT_CONTEXT,\n",
    "                                features=features_credit_card_balance_core)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.build_features(\n",
    "    anchor_list=[\n",
    "        anchor_installments_payments_core,\n",
    "        anchor_credit_card_balance_core\n",
    "        ], \n",
    "    derived_feature_list=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training data using point-in-time correct feature join\n",
    "\n",
    "A training dataset usually contains entity id columns, multiple feature columns, event timestamp column and label/target column. \n",
    "\n",
    "To create a training dataset using Feathr, one needs to provide a feature join configuration file to specify\n",
    "what features and how these features should be joined to the observation data. The feature join config file mainly contains: \n",
    "\n",
    "1. The path of a dataset as the 'spine' for the to-be-created training dataset. We call this input 'spine' dataset the 'observation'\n",
    "   dataset. Typically, each row of the observation data contains: \n",
    "   a) Column(s) representing entity id(s), which will be used as the join key to look up(join) feature value. \n",
    "   b) A column representing the event time of the row. By default, Feathr will make sure the feature values joined have\n",
    "   a timestamp earlier than it, ensuring no data leakage in the resulting training dataset. \n",
    "   c) Other columns will be simply pass through onto the output training dataset.\n",
    "2. The key fields from the observation data, which are used to joined with the feature data.\n",
    "3. List of feature names to be joined with the observation data. The features must be defined in the feature\n",
    "   definition configs.\n",
    "4. The time information of the observation data used to compare with the feature's timestamp during the join.\n",
    "\n",
    "Create training dataset via:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 09:53:13.989 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:62 - Uploading /var/folders/gs/dbrzk90d0m3849n982_q27w40000gn/T/tmp8pnag696/feathr_pyspark_driver.py to cloud..\n",
      "2022-07-07 09:53:13.990 | INFO     | feathr._synapse_submission:upload_file:360 - Uploading file feathr_pyspark_driver.py\n",
      "2022-07-07 09:53:16.328 | INFO     | feathr._synapse_submission:upload_file:366 - /var/folders/gs/dbrzk90d0m3849n982_q27w40000gn/T/tmp8pnag696/feathr_pyspark_driver.py is uploaded to location: abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/feathr_pyspark_driver.py\n",
      "2022-07-07 09:53:16.329 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:65 - /var/folders/gs/dbrzk90d0m3849n982_q27w40000gn/T/tmp8pnag696/feathr_pyspark_driver.py is uploaded to location: abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/feathr_pyspark_driver.py\n",
      "2022-07-07 09:53:16.357 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:62 - Uploading /var/folders/gs/dbrzk90d0m3849n982_q27w40000gn/T/tmp8pnag696/feature_join_conf/feature_join.conf to cloud..\n",
      "2022-07-07 09:53:16.358 | INFO     | feathr._synapse_submission:upload_file:360 - Uploading file feature_join.conf\n",
      "2022-07-07 09:53:17.453 | INFO     | feathr._synapse_submission:upload_file:366 - /var/folders/gs/dbrzk90d0m3849n982_q27w40000gn/T/tmp8pnag696/feature_join_conf/feature_join.conf is uploaded to location: abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/feature_join.conf\n",
      "2022-07-07 09:53:17.454 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:65 - /var/folders/gs/dbrzk90d0m3849n982_q27w40000gn/T/tmp8pnag696/feature_join_conf/feature_join.conf is uploaded to location: abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/feature_join.conf\n",
      "2022-07-07 09:53:17.455 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:62 - Uploading /var/folders/gs/dbrzk90d0m3849n982_q27w40000gn/T/tmp8pnag696/feature_conf/ to cloud..\n",
      "2022-07-07 09:53:17.455 | INFO     | feathr._synapse_submission:upload_file_to_workdir:348 - Uploading folder /var/folders/gs/dbrzk90d0m3849n982_q27w40000gn/T/tmp8pnag696/feature_conf/\n",
      "2022-07-07 09:53:17.458 | INFO     | feathr._synapse_submission:upload_file:360 - Uploading file auto_generated_request_features.conf\n",
      "2022-07-07 09:53:18.591 | INFO     | feathr._synapse_submission:upload_file:366 - /private/var/folders/gs/dbrzk90d0m3849n982_q27w40000gn/T/tmp8pnag696/feature_conf/auto_generated_request_features.conf is uploaded to location: abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/auto_generated_request_features.conf\n",
      "2022-07-07 09:53:18.592 | INFO     | feathr._synapse_submission:upload_file:360 - Uploading file auto_generated_anchored_features.conf\n",
      "2022-07-07 09:53:19.805 | INFO     | feathr._synapse_submission:upload_file:366 - /private/var/folders/gs/dbrzk90d0m3849n982_q27w40000gn/T/tmp8pnag696/feature_conf/auto_generated_anchored_features.conf is uploaded to location: abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/auto_generated_anchored_features.conf\n",
      "2022-07-07 09:53:19.807 | INFO     | feathr._synapse_submission:upload_file:360 - Uploading file auto_generated_derived_features.conf\n",
      "2022-07-07 09:53:20.999 | INFO     | feathr._synapse_submission:upload_file:366 - /private/var/folders/gs/dbrzk90d0m3849n982_q27w40000gn/T/tmp8pnag696/feature_conf/auto_generated_derived_features.conf is uploaded to location: abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/auto_generated_derived_features.conf\n",
      "2022-07-07 09:53:21.001 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:65 - /var/folders/gs/dbrzk90d0m3849n982_q27w40000gn/T/tmp8pnag696/feature_conf/ is uploaded to location: abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/auto_generated_request_features.conf,abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/auto_generated_anchored_features.conf,abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/auto_generated_derived_features.conf\n",
      "2022-07-07 09:53:21.002 | INFO     | feathr._envvariableutil:get_environment_variable:66 - S3_ACCESS_KEY is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-07-07 09:53:21.003 | INFO     | feathr._envvariableutil:get_environment_variable:66 - S3_SECRET_KEY is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-07-07 09:53:21.004 | INFO     | feathr._envvariableutil:get_environment_variable:66 - ADLS_ACCOUNT is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-07-07 09:53:21.006 | INFO     | feathr._envvariableutil:get_environment_variable:66 - ADLS_KEY is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-07-07 09:53:21.007 | INFO     | feathr._envvariableutil:get_environment_variable:66 - BLOB_ACCOUNT is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-07-07 09:53:21.007 | INFO     | feathr._envvariableutil:get_environment_variable:66 - BLOB_KEY is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-07-07 09:53:21.008 | INFO     | feathr._envvariableutil:get_environment_variable:66 - JDBC_TABLE is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-07-07 09:53:21.009 | INFO     | feathr._envvariableutil:get_environment_variable:66 - JDBC_USER is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-07-07 09:53:21.010 | INFO     | feathr._envvariableutil:get_environment_variable:66 - JDBC_PASSWORD is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-07-07 09:53:21.010 | INFO     | feathr._envvariableutil:get_environment_variable:66 - JDBC_DRIVER is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-07-07 09:53:21.011 | INFO     | feathr._envvariableutil:get_environment_variable:66 - JDBC_AUTH_FLAG is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-07-07 09:53:21.012 | INFO     | feathr._envvariableutil:get_environment_variable:66 - JDBC_TOKEN is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-07-07 09:53:21.038 | INFO     | feathr._envvariableutil:get_environment_variable:66 - JDBC_SF_PASSWORD is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-07-07 09:53:21.038 | INFO     | feathr._synapse_submission:submit_feathr_job:105 - Uploading jar from wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar to cloud for running job: feathr_home_credit_feathr_feature_join_job\n",
      "2022-07-07 09:53:21.039 | INFO     | feathr._synapse_submission:upload_file_to_workdir:343 - Skipping file wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar as it's already in the cloud\n",
      "2022-07-07 09:53:21.039 | INFO     | feathr._synapse_submission:submit_feathr_job:108 - wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar is uploaded to wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar for running job: feathr_home_credit_feathr_feature_join_job\n",
      "2022-07-07 09:53:22.791 | INFO     | feathr._synapse_submission:submit_feathr_job:124 - See submitted job here: https://web.azuresynapse.net/en-us/monitoring/sparkapplication\n",
      "2022-07-07 09:53:23.072 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: not_started\n",
      "2022-07-07 09:53:53.351 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: not_started\n",
      "2022-07-07 09:54:23.706 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: not_started\n",
      "2022-07-07 09:54:53.987 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: not_started\n",
      "2022-07-07 09:55:24.300 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: not_started\n",
      "2022-07-07 09:55:54.582 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: not_started\n",
      "2022-07-07 09:56:24.865 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: starting\n",
      "2022-07-07 09:56:55.146 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: starting\n",
      "2022-07-07 09:57:25.469 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: running\n",
      "2022-07-07 09:57:55.777 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: running\n",
      "2022-07-07 09:58:26.110 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: running\n",
      "2022-07-07 09:58:56.413 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: running\n",
      "2022-07-07 09:59:26.720 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: running\n",
      "2022-07-07 09:59:57.018 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: running\n",
      "2022-07-07 10:00:27.331 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: running\n",
      "2022-07-07 10:00:57.611 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: running\n",
      "2022-07-07 10:01:27.898 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: running\n",
      "2022-07-07 10:01:58.189 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: running\n",
      "2022-07-07 10:02:28.487 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: success\n"
     ]
    }
   ],
   "source": [
    "feature_queries = [\n",
    "    FeatureQuery(\n",
    "        feature_list=[\n",
    "            \"f_SK_ID_PREV\",\n",
    "            \"f_SK_ID_CURR\",\n",
    "            \"f_NUM_INSTALMENT_VERSION\",\n",
    "            \"f_NUM_INSTALMENT_NUMBER\",\n",
    "            \"f_DAYS_INSTALMENT\",\n",
    "            \"f_DAYS_ENTRY_PAYMENT\",\n",
    "            \"f_AMT_INSTALMENT\",\n",
    "            \"f_AMT_PAYMENT\",\n",
    "\n",
    "            \"f_AMT_UNPAID\"\n",
    "           \n",
    "        ], key=key_SK_ID_CURR),\n",
    "    FeatureQuery(\n",
    "        feature_list=[\n",
    "            # \"f_SK_ID_PREV\",\n",
    "            \"f_SK_ID_CURR_CC\",\n",
    "            \"f_MONTHS_BALANCE\",\n",
    "            \"f_AMT_BALANCE\",\n",
    "            \"f_AMT_CREDIT_LIMIT_ACTUAL\",\n",
    "            \"f_AMT_DRAWINGS_ATM_CURRENT\",\n",
    "            \"f_AMT_DRAWINGS_CURRENT\",\n",
    "            \"f_AMT_DRAWINGS_OTHER_CURRENT\",\n",
    "            \"f_AMT_DRAWINGS_POS_CURRENT\",\n",
    "            \"f_AMT_INST_MIN_REGULARITY\",\n",
    "            \"f_AMT_PAYMENT_CURRENT\",\n",
    "            \"f_AMT_PAYMENT_TOTAL_CURRENT\",\n",
    "            \"f_AMT_RECEIVABLE_PRINCIPAL\",\n",
    "            \"f_AMT_RECIVABLE\",\n",
    "            \"f_AMT_TOTAL_RECEIVABLE\",\n",
    "            \"f_CNT_DRAWINGS_ATM_CURRENT\",\n",
    "            \"f_CNT_DRAWINGS_CURRENT\",\n",
    "            \"f_CNT_DRAWINGS_OTHER_CURRENT\",\n",
    "            \"f_CNT_DRAWINGS_POS_CURRENT\",\n",
    "            \"f_CNT_INSTALMENT_MATURE_CUM\",\n",
    "            \"f_NAME_CONTRACT_STATUS\",\n",
    "            \"f_SK_DPD\",\n",
    "            \"f_SK_DPD_DEF\",\n",
    "\n",
    "            \"f_CREDIT_CARD_BALANCE_EMA_AVG\"\n",
    "        ], key=key_SK_ID_CURR),\n",
    "]\n",
    "\n",
    "\n",
    "settings = ObservationSettings(\n",
    "    observation_path=\"abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/home_credit_data/installments_payments.csv\",\n",
    "    event_timestamp_column=\"1609472084\",\n",
    "    timestamp_format=\"epoch\"\n",
    ")\n",
    "\n",
    "client.get_offline_features(observation_settings=settings,\n",
    "                            feature_query=feature_queries,\n",
    "                            output_path=\"abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/home_credit_data/output_installment-payment_credit_card_balance.avro\")\n",
    "client.wait_job_to_finish(timeout_sec=7200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the result and show the result\n",
    "\n",
    "Let's use the helper function `get_result_df` to download the result and view it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 10:02:28.837 | INFO     | feathr._synapse_submission:wait_for_completion:134 - Current Spark job status: success\n",
      "2022-07-07 10:02:29.434 | INFO     | feathr._synapse_submission:download_file:378 - Beginning reading of results from abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/home_credit_data/output_installment-payment_credit_card_balance.avro\n",
      "Downloading result files: 100%|██████████| 201/201 [07:22<00:00,  2.20s/it]\n",
      "2022-07-07 10:09:53.786 | INFO     | feathr._synapse_submission:download_file:407 - Finish downloading files from abfss://feathrhomecreditcafs@feathrhomecreditcasto.dfs.core.windows.net/home_credit_data/output_installment-payment_credit_card_balance.avro to ../../results/output_installment-payment_credit_card_balance.avro.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "def get_result_df(client: FeathrClient) -> pd.DataFrame:\n",
    "    \"\"\"Download the job result dataset from cloud as a Pandas dataframe.\"\"\"\n",
    "    res_url = client.get_job_result_uri(block=True, timeout_sec=600)\n",
    "    tmp_dir = \"../../../results/output_installment-payment_credit_card_balance.avro\"\n",
    "    shutil.rmtree(tmp_dir, ignore_errors=True)\n",
    "    client.feathr_spark_laucher.download_result(result_path=res_url, local_folder=tmp_dir)\n",
    "    dataframe_list = []\n",
    "    # assuming the result are in avro format\n",
    "    for file in glob.glob(os.path.join(tmp_dir, '*.avro')):\n",
    "        dataframe_list.append(pdx.read_avro(file))\n",
    "    vertical_concat_df = pd.concat(dataframe_list, axis=0)\n",
    "    return vertical_concat_df\n",
    "\n",
    "df_res = get_result_df(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SK_ID_PREV SK_ID_CURR NUM_INSTALMENT_VERSION NUM_INSTALMENT_NUMBER  \\\n",
      "0        2525854     100309                    1.0                     7   \n",
      "1        2525854     100309                    1.0                     5   \n",
      "2        2525854     100309                    1.0                     3   \n",
      "3        2525854     100309                    1.0                     1   \n",
      "4        2525854     100309                    1.0                     2   \n",
      "...          ...        ...                    ...                   ...   \n",
      "67081    1460610     455971                    1.0                    10   \n",
      "67082    2099905     455971                    1.0                     2   \n",
      "67083    1589506     455971                    1.0                    16   \n",
      "67084    2749130     455971                    1.0                     3   \n",
      "67085    2749130     455971                    1.0                    15   \n",
      "\n",
      "      DAYS_INSTALMENT DAYS_ENTRY_PAYMENT AMT_INSTALMENT AMT_PAYMENT  \\\n",
      "0               -78.0              -94.0      10781.325   10781.325   \n",
      "1              -138.0             -159.0      10781.325   10781.325   \n",
      "2              -198.0             -214.0      10781.325   10781.325   \n",
      "3              -258.0             -281.0      10781.325   10781.325   \n",
      "4              -228.0             -242.0      10781.325   10781.325   \n",
      "...               ...                ...            ...         ...   \n",
      "67081         -1894.0            -1914.0       23009.58    23009.58   \n",
      "67082         -1756.0            -1764.0       19837.35    19837.35   \n",
      "67083         -1237.0            -1246.0        12280.5     12280.5   \n",
      "67084          -613.0             -646.0       66878.28    66878.28   \n",
      "67085          -253.0             -282.0       66878.28       2.925   \n",
      "\n",
      "      f_NUM_INSTALMENT_VERSION f_NUM_INSTALMENT_NUMBER  ...  \\\n",
      "0                          1.0                       7  ...   \n",
      "1                          1.0                       7  ...   \n",
      "2                          1.0                       7  ...   \n",
      "3                          1.0                       7  ...   \n",
      "4                          1.0                       7  ...   \n",
      "...                        ...                     ...  ...   \n",
      "67081                      1.0                       9  ...   \n",
      "67082                      1.0                       9  ...   \n",
      "67083                      1.0                       9  ...   \n",
      "67084                      1.0                       9  ...   \n",
      "67085                      1.0                       9  ...   \n",
      "\n",
      "      f_AMT_RECEIVABLE_PRINCIPAL f_AMT_PAYMENT_TOTAL_CURRENT  \\\n",
      "0                            0.0                         0.0   \n",
      "1                            0.0                         0.0   \n",
      "2                            0.0                         0.0   \n",
      "3                            0.0                         0.0   \n",
      "4                            0.0                         0.0   \n",
      "...                          ...                         ...   \n",
      "67081                        0.0                         0.0   \n",
      "67082                        0.0                         0.0   \n",
      "67083                        0.0                         0.0   \n",
      "67084                        0.0                         0.0   \n",
      "67085                        0.0                         0.0   \n",
      "\n",
      "      f_CREDIT_CARD_BALANCE_EMA_AVG f_SK_DPD_DEF f_CNT_DRAWINGS_OTHER_CURRENT  \\\n",
      "0                               0.0            0                         None   \n",
      "1                               0.0            0                         None   \n",
      "2                               0.0            0                         None   \n",
      "3                               0.0            0                         None   \n",
      "4                               0.0            0                         None   \n",
      "...                             ...          ...                          ...   \n",
      "67081            35381.861876514406            0                          0.0   \n",
      "67082            35381.861876514406            0                          0.0   \n",
      "67083            35381.861876514406            0                          0.0   \n",
      "67084            35381.861876514406            0                          0.0   \n",
      "67085            35381.861876514406            0                          0.0   \n",
      "\n",
      "      f_AMT_DRAWINGS_CURRENT f_NAME_CONTRACT_STATUS  \\\n",
      "0                        0.0                 Active   \n",
      "1                        0.0                 Active   \n",
      "2                        0.0                 Active   \n",
      "3                        0.0                 Active   \n",
      "4                        0.0                 Active   \n",
      "...                      ...                    ...   \n",
      "67081                    0.0                 Active   \n",
      "67082                    0.0                 Active   \n",
      "67083                    0.0                 Active   \n",
      "67084                    0.0                 Active   \n",
      "67085                    0.0                 Active   \n",
      "\n",
      "      f_CNT_DRAWINGS_POS_CURRENT f_AMT_CREDIT_LIMIT_ACTUAL f_SK_ID_CURR_CC  \n",
      "0                           None                     45000          100309  \n",
      "1                           None                     45000          100309  \n",
      "2                           None                     45000          100309  \n",
      "3                           None                     45000          100309  \n",
      "4                           None                     45000          100309  \n",
      "...                          ...                       ...             ...  \n",
      "67081                        0.0                         0          455971  \n",
      "67082                        0.0                         0          455971  \n",
      "67083                        0.0                         0          455971  \n",
      "67084                        0.0                         0          455971  \n",
      "67085                        0.0                         0          455971  \n",
      "\n",
      "[13605401 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f_SK_ID_PREV f_SK_ID_CURR       f_AMT_UNPAID  \\\n",
      "0          2525854       100309                0.0   \n",
      "1          2525854       100309                0.0   \n",
      "2          2525854       100309                0.0   \n",
      "3          2525854       100309                0.0   \n",
      "4          2525854       100309                0.0   \n",
      "...            ...          ...                ...   \n",
      "67081      1589506       455971  743.5050000000001   \n",
      "67082      1589506       455971  743.5050000000001   \n",
      "67083      1589506       455971  743.5050000000001   \n",
      "67084      1589506       455971  743.5050000000001   \n",
      "67085      1589506       455971  743.5050000000001   \n",
      "\n",
      "      f_CREDIT_CARD_BALANCE_EMA_AVG  \n",
      "0                               0.0  \n",
      "1                               0.0  \n",
      "2                               0.0  \n",
      "3                               0.0  \n",
      "4                               0.0  \n",
      "...                             ...  \n",
      "67081            35381.861876514406  \n",
      "67082            35381.861876514406  \n",
      "67083            35381.861876514406  \n",
      "67084            35381.861876514406  \n",
      "67085            35381.861876514406  \n",
      "\n",
      "[13605401 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with pd.option_context('display.max_columns', 50, 'display.max_rows', 50000):\n",
    "#    print(df_res.columns.values.tolist())\n",
    "   print(df_res[[\n",
    "       \"f_SK_ID_PREV\",\n",
    "        \"f_SK_ID_CURR\",\n",
    "        # \"f_NUM_INSTALMENT_VERSION\",\n",
    "        # \"f_NUM_INSTALMENT_NUMBER\",\n",
    "        # \"f_DAYS_INSTALMENT\",\n",
    "        # \"f_DAYS_ENTRY_PAYMENT\",\n",
    "        # \"f_AMT_INSTALMENT\",\n",
    "        # \"f_AMT_PAYMENT\",\n",
    "\n",
    "        \"f_AMT_UNPAID\",\n",
    "\n",
    "        # \"f_SK_ID_PREV\",\n",
    "        # \"f_SK_ID_CURR\",\n",
    "        # \"f_MONTHS_BALANCE\",\n",
    "        # \"f_AMT_BALANCE\",\n",
    "        # \"f_AMT_CREDIT_LIMIT_ACTUAL\",\n",
    "        # \"f_AMT_DRAWINGS_ATM_CURRENT\",\n",
    "        # \"f_AMT_DRAWINGS_CURRENT\",\n",
    "        # \"f_AMT_DRAWINGS_OTHER_CURRENT\",\n",
    "        # \"f_AMT_DRAWINGS_POS_CURRENT\",\n",
    "        # \"f_AMT_INST_MIN_REGULARITY\",\n",
    "        # \"f_AMT_PAYMENT_CURRENT\",\n",
    "        # \"f_AMT_PAYMENT_TOTAL_CURRENT\",\n",
    "        # \"f_AMT_RECEIVABLE_PRINCIPAL\",\n",
    "        # \"f_AMT_RECIVABLE\",\n",
    "        # \"f_AMT_TOTAL_RECEIVABLE\",\n",
    "        # \"f_CNT_DRAWINGS_ATM_CURRENT\",\n",
    "        # \"f_CNT_DRAWINGS_CURRENT\",\n",
    "        # \"f_CNT_DRAWINGS_OTHER_CURRENT\",\n",
    "        # \"f_CNT_DRAWINGS_POS_CURRENT\",\n",
    "        # \"f_CNT_INSTALMENT_MATURE_CUM\",\n",
    "        # \"f_NAME_CONTRACT_STATUS\",\n",
    "        # \"f_SK_DPD\",\n",
    "        # \"f_SK_DPD_DEF\",\n",
    "\n",
    "        \"f_CREDIT_CARD_BALANCE_EMA_AVG\"\n",
    "   ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "345a509dc56d979ac3261ff2283eab94d92c7e49c33244e182cdb66ed5bdbc50"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
