{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feathr Feature Store on Home Credit\n",
    "\n",
    "This notebook illustrates the use of Feature Store to create a model for home credits. It includes these steps:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite: Install Feathr\n",
    "\n",
    "Install Feathr using pip:\n",
    "\n",
    "`pip install -U feathr==0.7.2 pandavro scikit-learn`\n",
    "\n",
    "Or if you want to use the latest Feathr code from GitHub:\n",
    "\n",
    "`pip install -I git+https://github.com/linkedin/feathr.git#subdirectory=feathr_project pandavro scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U feathr==0.7.1 pandavro scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite: Configure the required environment\n",
    "\n",
    "In the first step (Provision cloud resources), you should have provisioned all the required cloud resources. If you use Feathr CLI to create a workspace, you should have a folder with a file called `feathr_config.yaml` in it with all the required configurations. Otherwise, update the configuration below.\n",
    "\n",
    "The code below will write this configuration string to a temporary location and load it to Feathr. Please still refer to [feathr_config.yaml](https://github.com/linkedin/feathr/blob/v0.7.2/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml) and use that as the source of truth. It should also have more explanations on the meaning of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCE_PREFIX = '<RESOURCE_PREFIX>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "yaml_config = f\"\"\"\n",
    "# Please refer to https://github.com/linkedin/feathr/blob/v0.7.2/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml for explanations on the meaning of each field.\n",
    "api_version: 1\n",
    "project_config:\n",
    "  project_name: 'feathr_home_credit'\n",
    "  required_environment_variables:\n",
    "    - 'REDIS_PASSWORD'\n",
    "    - 'AZURE_CLIENT_ID'\n",
    "    - 'AZURE_TENANT_ID'\n",
    "    - 'AZURE_CLIENT_SECRET'\n",
    "offline_store:\n",
    "  adls:\n",
    "    adls_enabled: true\n",
    "  wasb:\n",
    "    wasb_enabled: true\n",
    "  s3:\n",
    "    s3_enabled: false\n",
    "    s3_endpoint: 's3.amazonaws.com'\n",
    "  jdbc:\n",
    "    jdbc_enabled: false\n",
    "    jdbc_database: 'feathrtestdb'\n",
    "    jdbc_table: 'feathrtesttable'\n",
    "spark_config:\n",
    "  spark_cluster: 'azure_synapse'\n",
    "  spark_result_output_parts: '1'\n",
    "  azure_synapse:\n",
    "    dev_url: \"https://{RESOURCE_PREFIX}spark.dev.azuresynapse.net\"\n",
    "    pool_name: \"spark31\"\n",
    "    # workspace dir for storing all the required configuration files and the jar resources\n",
    "    workspace_dir: \"abfss://{RESOURCE_PREFIX}fs@{RESOURCE_PREFIX}sto.dfs.core.windows.net/\"\n",
    "    executor_size: \"Small\"\n",
    "    executor_num: 4\n",
    "    feathr_runtime_location: wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar\n",
    "  databricks:\n",
    "    workspace_instance_url: 'https://adb-6885802458123232.12.azuredatabricks.net/'\n",
    "    workspace_token_value: ''\n",
    "    config_template: {{'run_name':'','new_cluster':{{'spark_version':'9.1.x-scala2.12','node_type_id':'Standard_D3_v2','num_workers':2,'spark_conf':{{}}}},'libraries':[{{'jar':''}}],'spark_jar_task':{{'main_class_name':'','parameters':['']}}}}\n",
    "    work_dir: 'dbfs:/feathr_getting_started'\n",
    "    feathr_runtime_location: wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar\n",
    "online_store:\n",
    "  redis:\n",
    "    host: '{RESOURCE_PREFIX}redis.redis.cache.windows.net'\n",
    "    port: 6380\n",
    "    ssl_enabled: True\n",
    "feature_registry:\n",
    "  purview:\n",
    "    type_system_initialization: true\n",
    "    purview_name: '{RESOURCE_PREFIX}purview'\n",
    "    delimiter: '__'\n",
    "\"\"\"\n",
    "tmp = tempfile.NamedTemporaryFile(mode='w', delete=False)\n",
    "with open(tmp.name, \"w\") as text_file:\n",
    "    text_file.write(yaml_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the data\n",
    "\n",
    "In this tutorial, we use Feathr Feature Store to create a model that predicts NYC Taxi fares. The dataset comes from [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). The data is as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tempfile\n",
    "from datetime import datetime, timedelta\n",
    "from math import sqrt\n",
    "\n",
    "import pandas as pd\n",
    "import pandavro as pdx\n",
    "from feathr import FeathrClient\n",
    "from feathr import BOOLEAN, FLOAT, INT32, ValueType, STRING\n",
    "from feathr import Feature, DerivedFeature, FeatureAnchor\n",
    "from feathr import BackfillTime, MaterializationSettings\n",
    "from feathr import FeatureQuery, ObservationSettings\n",
    "from feathr import RedisSink\n",
    "from feathr import INPUT_CONTEXT, HdfsSource\n",
    "from feathr import WindowAggTransformation\n",
    "from feathr import TypedKey\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup necessary environment variables\n",
    "\n",
    "You have to setup the environment variables in order to run this sample. More environment variables can be set by referring to [feathr_config.yaml](https://github.com/linkedin/feathr/blob/v0.7.2/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml) and use that as the source of truth. It should also have more explanations on the meaning of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['REDIS_PASSWORD'] = ''\n",
    "os.environ['AZURE_CLIENT_ID'] = ''\n",
    "os.environ['AZURE_TENANT_ID'] = '' \n",
    "os.environ['AZURE_CLIENT_SECRET'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will initialize a feathr client:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = FeathrClient(config_path=tmp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc pre-processing methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalments payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def installments_payments_preprocessing(df: DataFrame) -> DataFrame:\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    from pyspark import sql\n",
    "\n",
    "    def aggAvgInstalments(df):\n",
    "        df_ = df.copy()\n",
    "        \n",
    "        \n",
    "        df_['AMT_INSTALMENT'] = pd.to_numeric(df_['AMT_INSTALMENT'])\n",
    "        df_['AMT_PAYMENT'] = pd.to_numeric(df_['AMT_PAYMENT'])\n",
    "        \n",
    "        df_['INSTALMENT_MISSED'] = (df_['AMT_INSTALMENT'] > df_['AMT_PAYMENT']).astype(int)\n",
    "        df_['AMT_UNPAID'] = df_['AMT_INSTALMENT'] - df_['AMT_PAYMENT']\n",
    "        df_['PERC_UNPAID'] = df_['AMT_UNPAID']/df_['AMT_INSTALMENT']\n",
    "        \n",
    "        df_ = df_.fillna(0)\n",
    "        agg = df_.groupby(\"SK_ID_CURR\")\n",
    "        # percentage of missed payments\n",
    "        missed_instalments = agg['INSTALMENT_MISSED'].agg(lambda x: x.sum()/x.count()). \\\n",
    "            reset_index().set_index(\"SK_ID_CURR\")\n",
    "        # percentage of payments difference for each missed payment\n",
    "        avg_percent_unpaid = agg['PERC_UNPAID'].mean().reset_index().set_index(\"SK_ID_CURR\")\n",
    "        # average payments difference for each missed payment\n",
    "        avg_unpaid = agg['AMT_UNPAID'].mean().reset_index().set_index(\"SK_ID_CURR\")\n",
    "        final_df = missed_instalments\n",
    "        final_df = final_df.join(avg_percent_unpaid, on='SK_ID_CURR')\n",
    "        final_df = final_df.join(avg_unpaid,on=\"SK_ID_CURR\")\n",
    "        return final_df\n",
    "\n",
    "    # add a TRAN_DATE column with a static date\n",
    "    df = df.withColumn(\"TRAN_DATE\", lit(datetime.datetime(2021,1,1,11,34,44).strftime('%Y-%m-%d %X')))\n",
    "\n",
    "    df_org = df.toPandas()\n",
    "\n",
    "    df_aggAvgInstalments = aggAvgInstalments(df_org)\n",
    "\n",
    "    # results df would be merge to the original df\n",
    "    df_result = pd.merge(df_org, df_aggAvgInstalments, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    # merging df with same column name would result a columnname with a suffix of `_x` and `_y`.\n",
    "    # Renaming the column name with suffix `_x` to retain the original column name\n",
    "    df_result.columns = df_result.columns.str.rstrip(\"_x\")\n",
    "\n",
    "    \n",
    "    # convert panda to spark dataframe\n",
    "    spark_session = sql.SparkSession.builder.appName(\"pdf to sdf\").getOrCreate()\n",
    "    \n",
    "    return spark_session.createDataFrame(df_result)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature definition for Instalments payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# source for pass through features\n",
    "# \"TRAN_DATE\" column created on on the \"datasource_prepocessing\" method.\n",
    "installments_payments_source_core = HdfsSource(name=\"instalmentsPaymentsSourceCore\",\n",
    "                          path=f\"abfss://{RESOURCE_PREFIX}fs@{RESOURCE_PREFIX}sto.dfs.core.windows.net/home_credit_data/installments_payments.csv\",\n",
    "                          preprocessing=installments_payments_preprocessing,\n",
    "                          event_timestamp_column=\"TRAN_DATE\",\n",
    "                          timestamp_format=\"yyyy-MM-dd HH:mm:ss\"\n",
    "                          )\n",
    "\n",
    "# key definition for instalments payments\n",
    "key_SK_ID_CURR = TypedKey(key_column=\"SK_ID_CURR\",\n",
    "                       key_column_type=ValueType.INT32,\n",
    "                       description=\"SK ID CURR\",\n",
    "                       full_name=\"installments_payments.SK_ID_CURR\")\n",
    "\n",
    "# pass through columns of Instalments payments CSV\n",
    "# columns Instalments payments\n",
    "f_SK_ID_PREV = Feature(name=\"f_SK_ID_PREV\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"SK_ID_PREV\")\n",
    "f_SK_ID_CURR = Feature(name=\"f_SK_ID_CURR\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"SK_ID_CURR\")\n",
    "f_NUM_INSTALMENT_VERSION = Feature(name=\"f_NUM_INSTALMENT_VERSION\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"NUM_INSTALMENT_VERSION\")\n",
    "f_NUM_INSTALMENT_NUMBER = Feature(name=\"f_NUM_INSTALMENT_NUMBER\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"NUM_INSTALMENT_NUMBER\")\n",
    "f_DAYS_INSTALMENT = Feature(name=\"f_DAYS_INSTALMENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"DAYS_INSTALMENT\")\n",
    "f_DAYS_ENTRY_PAYMENT = Feature(name=\"f_DAYS_ENTRY_PAYMENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"DAYS_ENTRY_PAYMENT\")\n",
    "f_AMT_INSTALMENT = Feature(name=\"f_AMT_INSTALMENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_INSTALMENT\")\n",
    "f_AMT_PAYMENT = Feature(name=\"f_AMT_PAYMENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_PAYMENT\")\n",
    "f_AMT_UNPAID = Feature(name=\"f_AMT_UNPAID\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_UNPAID\")\n",
    "                  \n",
    "\n",
    "features_installments_payments_core=[\n",
    "  f_SK_ID_PREV,\n",
    "  f_SK_ID_CURR,\n",
    "  f_NUM_INSTALMENT_VERSION,\n",
    "  f_NUM_INSTALMENT_NUMBER,\n",
    "  f_DAYS_INSTALMENT,\n",
    "  f_DAYS_ENTRY_PAYMENT,\n",
    "  f_AMT_INSTALMENT,\n",
    "  f_AMT_PAYMENT,\n",
    "\n",
    "  f_AMT_UNPAID\n",
    "  ]\n",
    "\n",
    "anchor_installments_payments_core = FeatureAnchor(name=\"anchor_installments_payments_core\",\n",
    "                                source=installments_payments_source_core,\n",
    "                                features=features_installments_payments_core)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_card_balance_preprocessing(df: DataFrame) -> DataFrame:\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    from pyspark import sql\n",
    "\n",
    "    def avgCreditBalance(df):\n",
    "        df['AMT_BALANCE'] = pd.to_numeric(df['AMT_BALANCE'])\n",
    "        return df.groupby('SK_ID_CURR')['AMT_BALANCE'].mean()\n",
    "    \n",
    "    def creditCardBalanceRollingBalance(df):\n",
    "        df_final = df.copy()\n",
    "        df_final = df_final.sort_values(by=\"MONTHS_BALANCE\")\n",
    "        df_final = df_final.groupby(\"SK_ID_CURR\")['AMT_BALANCE'].agg(\n",
    "            lambda x: x.ewm(span=x.shape[0], adjust=False).mean().mean()\n",
    "        )\n",
    "\n",
    "        df_final = df_final.reset_index(name=\"CREDIT_CARD_BALANCE_EMA_AVG\")\n",
    "        df_final = df_final.set_index('SK_ID_CURR')\n",
    "        return df_final\n",
    "    \n",
    "    def creditCardFeatures(credit_card_balance):\n",
    "        dfs = []\n",
    "        dfs.append(avgCreditBalance(credit_card_balance))\n",
    "        dfs.append(creditCardBalanceRollingBalance(credit_card_balance))\n",
    "        final_df = dfs.pop()\n",
    "        while dfs:\n",
    "            final_df = final_df.join(dfs.pop(),on='SK_ID_CURR')\n",
    "        return final_df\n",
    "\n",
    "    # add a TRAN_DATE column with a static date\n",
    "    df = df.withColumn(\"TRAN_DATE\", lit(datetime.datetime(2021,1,1,11,34,44).strftime('%Y-%m-%d %X')))\n",
    "    df_org = df.toPandas()\n",
    "\n",
    "    df_result = creditCardFeatures(df_org)\n",
    "\n",
    "    # results df would be merge to the original df\n",
    "    df_result = pd.merge(df_org, df_result, on=\"SK_ID_CURR\", how=\"left\")\n",
    "    # merging df with same column name would result a columnname with a suffix of `_x` and `_y`.\n",
    "    # Renaming the column name with suffix `_x` to retain the original column name\n",
    "    df_result.columns = df_result.columns.str.rstrip(\"_x\")\n",
    "    \n",
    "    # convert panda to spark dataframe\n",
    "    spark_session = sql.SparkSession.builder.appName(\"pdf to sdf\").getOrCreate()\n",
    "    \n",
    "    return spark_session.createDataFrame(df_result)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature definition for Credit Card Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# source for pass through features\n",
    "# \"TRAN_DATE\" column created on on the \"datasource_prepocessing\" method.\n",
    "credit_card_balance_source_core = HdfsSource(name=\"creditCardBalanceSourceCore\",\n",
    "                          path=f\"abfss://{RESOURCE_PREFIX}fs@{RESOURCE_PREFIX}sto.dfs.core.windows.net/home_credit_data/credit_card_balance.csv\",\n",
    "                          preprocessing=credit_card_balance_preprocessing,\n",
    "                          event_timestamp_column=\"TRAN_DATE\",\n",
    "                          timestamp_format=\"yyyy-MM-dd HH:mm:ss\"\n",
    "                          )\n",
    "\n",
    "# pass through columns of Instalments payments CSV\n",
    "# columns Instalments payments\n",
    "f_SK_ID_PREV = Feature(name=\"f_SK_ID_PREV\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"SK_ID_PREV\")\n",
    "f_SK_ID_CURR_CC = Feature(name=\"f_SK_ID_CURR_CC\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"SK_ID_CURR\")\n",
    "f_MONTHS_BALANCE = Feature(name=\"f_MONTHS_BALANCE\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"MONTHS_BALANCE\")\n",
    "f_AMT_BALANCE = Feature(name=\"f_AMT_BALANCE\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_BALANCE\")\n",
    "f_AMT_CREDIT_LIMIT_ACTUAL = Feature(name=\"f_AMT_CREDIT_LIMIT_ACTUAL\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_CREDIT_LIMIT_ACTUAL\")\n",
    "f_AMT_DRAWINGS_ATM_CURRENT = Feature(name=\"f_AMT_DRAWINGS_ATM_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_DRAWINGS_ATM_CURRENT\")\n",
    "f_AMT_DRAWINGS_CURRENT = Feature(name=\"f_AMT_DRAWINGS_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_DRAWINGS_CURRENT\")\n",
    "f_AMT_DRAWINGS_OTHER_CURRENT = Feature(name=\"f_AMT_DRAWINGS_OTHER_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_DRAWINGS_OTHER_CURRENT\")\n",
    "f_AMT_DRAWINGS_POS_CURRENT = Feature(name=\"f_AMT_DRAWINGS_POS_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_DRAWINGS_POS_CURRENT\")\n",
    "f_AMT_INST_MIN_REGULARITY = Feature(name=\"f_AMT_INST_MIN_REGULARITY\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_INST_MIN_REGULARITY\")\n",
    "f_AMT_PAYMENT_CURRENT = Feature(name=\"f_AMT_PAYMENT_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_PAYMENT_CURRENT\")\n",
    "f_AMT_PAYMENT_TOTAL_CURRENT = Feature(name=\"f_AMT_PAYMENT_TOTAL_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_PAYMENT_TOTAL_CURRENT\")\n",
    "f_AMT_RECEIVABLE_PRINCIPAL = Feature(name=\"f_AMT_RECEIVABLE_PRINCIPAL\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_RECEIVABLE_PRINCIPAL\")\n",
    "f_AMT_RECIVABLE = Feature(name=\"f_AMT_RECIVABLE\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_RECIVABLE\")\n",
    "f_AMT_TOTAL_RECEIVABLE = Feature(name=\"f_AMT_TOTAL_RECEIVABLE\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"AMT_TOTAL_RECEIVABLE\")\n",
    "f_CNT_DRAWINGS_ATM_CURRENT = Feature(name=\"f_CNT_DRAWINGS_ATM_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"CNT_DRAWINGS_ATM_CURRENT\")\n",
    "f_CNT_DRAWINGS_CURRENT = Feature(name=\"f_CNT_DRAWINGS_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"CNT_DRAWINGS_CURRENT\")\n",
    "f_CNT_DRAWINGS_OTHER_CURRENT = Feature(name=\"f_CNT_DRAWINGS_OTHER_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"CNT_DRAWINGS_OTHER_CURRENT\")\n",
    "f_CNT_DRAWINGS_POS_CURRENT = Feature(name=\"f_CNT_DRAWINGS_POS_CURRENT\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"CNT_DRAWINGS_POS_CURRENT\")\n",
    "f_CNT_INSTALMENT_MATURE_CUM = Feature(name=\"f_CNT_INSTALMENT_MATURE_CUM\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"CNT_INSTALMENT_MATURE_CUM\")\n",
    "f_NAME_CONTRACT_STATUS = Feature(name=\"f_NAME_CONTRACT_STATUS\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"NAME_CONTRACT_STATUS\")\n",
    "f_SK_DPD = Feature(name=\"f_SK_DPD\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"SK_DPD\")\n",
    "f_SK_DPD_DEF = Feature(name=\"f_SK_DPD_DEF\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"SK_DPD_DEF\")\n",
    "\n",
    "\n",
    "f_CREDIT_CARD_BALANCE_EMA_AVG = Feature(name=\"f_CREDIT_CARD_BALANCE_EMA_AVG\",\n",
    "                  key=key_SK_ID_CURR,\n",
    "                  feature_type=STRING,\n",
    "                  transform=\"CREDIT_CARD_BALANCE_EMA_AVG\")\n",
    "\n",
    "\n",
    "features_credit_card_balance_core=[\n",
    "  f_SK_ID_CURR_CC,\n",
    "  f_MONTHS_BALANCE,\n",
    "  f_AMT_BALANCE,\n",
    "  f_AMT_CREDIT_LIMIT_ACTUAL,\n",
    "  f_AMT_DRAWINGS_ATM_CURRENT,\n",
    "  f_AMT_DRAWINGS_CURRENT,\n",
    "  f_AMT_DRAWINGS_OTHER_CURRENT,\n",
    "  f_AMT_DRAWINGS_POS_CURRENT,\n",
    "  f_AMT_INST_MIN_REGULARITY,\n",
    "  f_AMT_PAYMENT_CURRENT,\n",
    "  f_AMT_PAYMENT_TOTAL_CURRENT,\n",
    "  f_AMT_RECEIVABLE_PRINCIPAL,\n",
    "  f_AMT_RECIVABLE,\n",
    "  f_AMT_TOTAL_RECEIVABLE,\n",
    "  f_CNT_DRAWINGS_ATM_CURRENT,\n",
    "  f_CNT_DRAWINGS_CURRENT,\n",
    "  f_CNT_DRAWINGS_OTHER_CURRENT,\n",
    "  f_CNT_DRAWINGS_POS_CURRENT,\n",
    "  f_CNT_INSTALMENT_MATURE_CUM,\n",
    "  f_NAME_CONTRACT_STATUS,\n",
    "  f_SK_DPD,\n",
    "  f_SK_DPD_DEF,\n",
    "\n",
    "  f_CREDIT_CARD_BALANCE_EMA_AVG\n",
    "\n",
    "  ]\n",
    "\n",
    "anchor_credit_card_balance_core = FeatureAnchor(name=\"anchor_credit_card_balance_core\",\n",
    "                                source=credit_card_balance_source_core,\n",
    "                                features=features_credit_card_balance_core)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.build_features(\n",
    "    anchor_list=[\n",
    "        anchor_installments_payments_core,\n",
    "        anchor_credit_card_balance_core\n",
    "        ], \n",
    "    derived_feature_list=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training data using point-in-time correct feature join\n",
    "\n",
    "A training dataset usually contains entity id columns, multiple feature columns, event timestamp column and label/target column. \n",
    "\n",
    "To create a training dataset using Feathr, one needs to provide a feature join configuration file to specify\n",
    "what features and how these features should be joined to the observation data. The feature join config file mainly contains: \n",
    "\n",
    "1. The path of a dataset as the 'spine' for the to-be-created training dataset. We call this input 'spine' dataset the 'observation'\n",
    "   dataset. Typically, each row of the observation data contains: \n",
    "   a) Column(s) representing entity id(s), which will be used as the join key to look up(join) feature value. \n",
    "   b) A column representing the event time of the row. By default, Feathr will make sure the feature values joined have\n",
    "   a timestamp earlier than it, ensuring no data leakage in the resulting training dataset. \n",
    "   c) Other columns will be simply pass through onto the output training dataset.\n",
    "2. The key fields from the observation data, which are used to joined with the feature data.\n",
    "3. List of feature names to be joined with the observation data. The features must be defined in the feature\n",
    "   definition configs.\n",
    "4. The time information of the observation data used to compare with the feature's timestamp during the join.\n",
    "\n",
    "Create training dataset via:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_queries = [\n",
    "    FeatureQuery(\n",
    "        feature_list=[\n",
    "            \"f_SK_ID_PREV\",\n",
    "            \"f_SK_ID_CURR\",\n",
    "            \"f_NUM_INSTALMENT_VERSION\",\n",
    "            \"f_NUM_INSTALMENT_NUMBER\",\n",
    "            \"f_DAYS_INSTALMENT\",\n",
    "            \"f_DAYS_ENTRY_PAYMENT\",\n",
    "            \"f_AMT_INSTALMENT\",\n",
    "            \"f_AMT_PAYMENT\",\n",
    "\n",
    "            \"f_AMT_UNPAID\"\n",
    "        ], key=key_SK_ID_CURR),\n",
    "    FeatureQuery(\n",
    "        feature_list=[\n",
    "            \"f_SK_ID_CURR_CC\",\n",
    "            \"f_MONTHS_BALANCE\",\n",
    "            \"f_AMT_BALANCE\",\n",
    "            \"f_AMT_CREDIT_LIMIT_ACTUAL\",\n",
    "            \"f_AMT_DRAWINGS_ATM_CURRENT\",\n",
    "            \"f_AMT_DRAWINGS_CURRENT\",\n",
    "            \"f_AMT_DRAWINGS_OTHER_CURRENT\",\n",
    "            \"f_AMT_DRAWINGS_POS_CURRENT\",\n",
    "            \"f_AMT_INST_MIN_REGULARITY\",\n",
    "            \"f_AMT_PAYMENT_CURRENT\",\n",
    "            \"f_AMT_PAYMENT_TOTAL_CURRENT\",\n",
    "            \"f_AMT_RECEIVABLE_PRINCIPAL\",\n",
    "            \"f_AMT_RECIVABLE\",\n",
    "            \"f_AMT_TOTAL_RECEIVABLE\",\n",
    "            \"f_CNT_DRAWINGS_ATM_CURRENT\",\n",
    "            \"f_CNT_DRAWINGS_CURRENT\",\n",
    "            \"f_CNT_DRAWINGS_OTHER_CURRENT\",\n",
    "            \"f_CNT_DRAWINGS_POS_CURRENT\",\n",
    "            \"f_CNT_INSTALMENT_MATURE_CUM\",\n",
    "            \"f_NAME_CONTRACT_STATUS\",\n",
    "            \"f_SK_DPD\",\n",
    "            \"f_SK_DPD_DEF\",\n",
    "\n",
    "            \"f_CREDIT_CARD_BALANCE_EMA_AVG\"\n",
    "        ], key=key_SK_ID_CURR),\n",
    "]\n",
    "\n",
    "\n",
    "settings = ObservationSettings(\n",
    "    observation_path=f\"abfss://{RESOURCE_PREFIX}fs@{RESOURCE_PREFIX}sto.dfs.core.windows.net/home_credit_data/installments_payments.csv\",\n",
    "    event_timestamp_column=\"1609472084\",\n",
    "    timestamp_format=\"epoch\"\n",
    ")\n",
    "\n",
    "client.get_offline_features(observation_settings=settings,\n",
    "                            feature_query=feature_queries,\n",
    "                            output_path=f\"abfss://{RESOURCE_PREFIX}fs@{RESOURCE_PREFIX}sto.dfs.core.windows.net/home_credit_data/output_instalment-payment_credit_card_balance.avro\")\n",
    "client.wait_job_to_finish(timeout_sec=7200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the result and show the result\n",
    "\n",
    "Let's use the helper function `get_result_df` to download the result and view it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def get_result_df(client: FeathrClient) -> pd.DataFrame:\n",
    "    \"\"\"Download the job result dataset from cloud as a Pandas dataframe.\"\"\"\n",
    "    res_url = client.get_job_result_uri(block=True, timeout_sec=600)\n",
    "    tmp_dir = \"../output_instalment-payment_credit_card_balance.avro\"\n",
    "    shutil.rmtree(tmp_dir, ignore_errors=True)\n",
    "    client.feathr_spark_launcher.download_result(result_path=res_url, local_folder=tmp_dir)\n",
    "    dataframe_list = []\n",
    "    # assuming the result are in avro format\n",
    "    for file in glob.glob(os.path.join(tmp_dir, '*.avro')):\n",
    "        dataframe_list.append(pdx.read_avro(file))\n",
    "    vertical_concat_df = pd.concat(dataframe_list, axis=0)\n",
    "    return vertical_concat_df\n",
    "\n",
    "df_res = get_result_df(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pd.option_context('display.max_columns', 50, 'display.max_rows', 1000):\n",
    "   print(df_res[[\n",
    "       \"f_SK_ID_PREV\",\n",
    "        \"f_SK_ID_CURR\",\n",
    "        \"f_NUM_INSTALMENT_VERSION\",\n",
    "        \"f_NUM_INSTALMENT_NUMBER\",\n",
    "        \"f_DAYS_INSTALMENT\",\n",
    "        \"f_DAYS_ENTRY_PAYMENT\",\n",
    "        \"f_AMT_INSTALMENT\",\n",
    "        \"f_AMT_PAYMENT\",\n",
    "\n",
    "        \"f_AMT_UNPAID\",\n",
    "\n",
    "        \"f_SK_ID_PREV\",\n",
    "        \"f_SK_ID_CURR\",\n",
    "        \"f_MONTHS_BALANCE\",\n",
    "        \"f_AMT_BALANCE\",\n",
    "        \"f_AMT_CREDIT_LIMIT_ACTUAL\",\n",
    "        \"f_AMT_DRAWINGS_ATM_CURRENT\",\n",
    "        \"f_AMT_DRAWINGS_CURRENT\",\n",
    "        \"f_AMT_DRAWINGS_OTHER_CURRENT\",\n",
    "        \"f_AMT_DRAWINGS_POS_CURRENT\",\n",
    "        \"f_AMT_INST_MIN_REGULARITY\",\n",
    "        \"f_AMT_PAYMENT_CURRENT\",\n",
    "        \"f_AMT_PAYMENT_TOTAL_CURRENT\",\n",
    "        \"f_AMT_RECEIVABLE_PRINCIPAL\",\n",
    "        \"f_AMT_RECIVABLE\",\n",
    "        \"f_AMT_TOTAL_RECEIVABLE\",\n",
    "        \"f_CNT_DRAWINGS_ATM_CURRENT\",\n",
    "        \"f_CNT_DRAWINGS_CURRENT\",\n",
    "        \"f_CNT_DRAWINGS_OTHER_CURRENT\",\n",
    "        \"f_CNT_DRAWINGS_POS_CURRENT\",\n",
    "        \"f_CNT_INSTALMENT_MATURE_CUM\",\n",
    "        \"f_NAME_CONTRACT_STATUS\",\n",
    "        \"f_SK_DPD\",\n",
    "        \"f_SK_DPD_DEF\",\n",
    "\n",
    "        \"f_CREDIT_CARD_BALANCE_EMA_AVG\"\n",
    "   ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backfill_time = BackfillTime(start=datetime(2020, 5, 20), \n",
    "                             end=datetime(2020, 5, 20), \n",
    "                             step=timedelta(days=1))\n",
    "redisSink = RedisSink(table_name=\"homeCreditDemoFeature\")\n",
    "settings = MaterializationSettings(name=\"homeCreditFeatureSetting\",\n",
    "                                   backfill_time=backfill_time,\n",
    "                                   sinks=[redisSink],\n",
    "                                   feature_names=[\"f_CREDIT_CARD_BALANCE_EMA_AVG\"])\n",
    "\n",
    "client.materialize_features(settings)\n",
    "client.wait_job_to_finish(timeout_sec=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_online_features('homeCreditDemoFeature', \n",
    "                           '456042', \n",
    "                           ['f_CREDIT_CARD_BALANCE_EMA_AVG'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd8e05a3b29cb52c25a673b02199ba49a1ae4abbf3dc61fdb468ec9ed0117842"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
